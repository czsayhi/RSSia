# RSSæ™ºèƒ½è®¢é˜…å™¨ - AIæœåŠ¡æ¶æ„è§„èŒƒ

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|------|------|
| **æ–‡æ¡£ç‰ˆæœ¬** | v1.0 |
| **åˆ›å»ºæ—¥æœŸ** | 2024-12-19 |
| **æœ€åæ›´æ–°** | 2024-12-19 |
| **æ–‡æ¡£çŠ¶æ€** | è®¾è®¡é˜¶æ®µ |
| **è´Ÿè´£äºº** | å¼€å‘å›¢é˜Ÿ |

## ğŸ¯ æ¦‚è¿°

RSSæ™ºèƒ½è®¢é˜…å™¨AIæœåŠ¡æ¶æ„æ—¨åœ¨ä¸ºç”¨æˆ·æä¾›æ™ºèƒ½å†…å®¹é¢„å¤„ç†ã€ä¸ªæ€§åŒ–æ—¥æŠ¥ç”Ÿæˆå’Œæ™ºèƒ½å¯¹è¯æœåŠ¡ã€‚æœ¬æ¶æ„åŸºäºæœ¬åœ°åŒ–éƒ¨ç½²ï¼Œç¡®ä¿æ•°æ®å®‰å…¨å’Œæˆæœ¬æ§åˆ¶ï¼Œé€šè¿‡å¤šå±‚å®‰å…¨é˜²æŠ¤å’Œç›´æ¥è¯­ä¹‰æ£€ç´¢ï¼Œæä¾›å¯é çš„AIå¢å¼ºåŠŸèƒ½ã€‚

### æ ¸å¿ƒç›®æ ‡

- **æ™ºèƒ½å†…å®¹é¢„å¤„ç†**ï¼šè‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾ã€ä¸»é¢˜ã€æ‘˜è¦
- **ä¸ªæ€§åŒ–æ—¥æŠ¥**ï¼šåŸºäºç”¨æˆ·è®¢é˜…å†…å®¹ç”Ÿæˆæ¯æ—¥æŠ¥å‘Š
- **æ™ºèƒ½å¯¹è¯**ï¼šåŸºäºRAGæ¶æ„çš„å†…å®¹é—®ç­”ç³»ç»Ÿ
- **å®‰å…¨å¯æ§**ï¼šå¤šå±‚é˜²æŠ¤ï¼Œé¿å…æ¶æ„åˆ©ç”¨
- **æœ¬åœ°åŒ–éƒ¨ç½²**ï¼šé›¶APIæˆæœ¬ï¼Œæ•°æ®ä¸å‡ºæœ¬åœ°

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### ç³»ç»Ÿæ¶æ„æ€»è§ˆ

  ```mermaid
  graph TB
      %% æ•°æ®è¾“å…¥å±‚
      subgraph Input ["ğŸ“¥ æ•°æ®è¾“å…¥å±‚"]
          RSS["RSSå†…å®¹å…¥åº“"]
          UserQuery["ç”¨æˆ·å¯¹è¯è¯·æ±‚"]
          Schedule["å®šæ—¶ä»»åŠ¡è§¦å‘"]
      end
      
      %% AIå¤„ç†æ ¸å¿ƒ
      subgraph AICore ["ğŸ§  AIå¤„ç†æ ¸å¿ƒ"]
          PreProcessor["AIé¢„å¤„ç†æœåŠ¡<br/>æ ‡ç­¾æ‘˜è¦ç”Ÿæˆ"]
          ConversationEngine["å¯¹è¯å¤„ç†å¼•æ“<br/>å‘é‡æ£€ç´¢+æ™ºèƒ½å›ç­”"]
          ReportGenerator["æ—¥æŠ¥ç”Ÿæˆå™¨<br/>å†…å®¹èšåˆ+æ‘˜è¦"]
          PromptEngine["Promptç”Ÿæˆå¼•æ“<br/>ä¸‰åœºæ™¯ç»Ÿä¸€ç®¡ç†"]
      end
      
      %% AIæ¨¡å‹å±‚
      subgraph Models ["ğŸ¤– AIæ¨¡å‹å±‚"]
          LLM["Qwen2.5-7B-Instruct<br/>æœ¬åœ°éƒ¨ç½²"]
          VectorModel["Sentence Transformers<br/>768ç»´å‘é‡"]
      end
      
      %% å®‰å…¨å’Œæ€§èƒ½å±‚
      subgraph Security ["ğŸ›¡ï¸ å®‰å…¨ä¸æ€§èƒ½å±‚"]
          SecurityFilter["å®‰å…¨è¿‡æ»¤å™¨<br/>é»‘åå•+æ³¨å…¥æ£€æµ‹"]
          PerformanceManager["æ€§èƒ½ç®¡ç†å™¨<br/>ç¼“å­˜+å¹¶å‘+ç›‘æ§"]
          FallbackHandler["å…œåº•å¤„ç†å™¨<br/>å¼‚å¸¸åœºæ™¯å¤„ç†"]
      end
      
      %% å­˜å‚¨å±‚
      subgraph Storage ["ğŸ’¾ å­˜å‚¨å±‚"]
          SQLite[("SQLiteæ•°æ®åº“<br/>å†…å®¹+AIæ•°æ®")]
          ChromaDB[("ChromaDBå‘é‡åº“<br/>è¯­ä¹‰æ£€ç´¢")]
          Cache[("Redisç¼“å­˜<br/>å¯¹è¯+ä¼šè¯")]
      end
      
      %% é…ç½®å±‚
      subgraph Config ["âš™ï¸ é…ç½®å±‚"]
          TemplateLib["æ¨¡æ¿åº“<br/>Promptæ¨¡æ¿ç®¡ç†"]
          BlacklistLib["é»‘åå•åº“<br/>å®‰å…¨è§„åˆ™é…ç½®"]
          ConfigManager["é…ç½®ç®¡ç†å™¨<br/>ç³»ç»Ÿå‚æ•°è°ƒä¼˜"]
      end
      
      %% ä¸»è¦æ•°æ®æµ
      RSS --> PreProcessor
      UserQuery --> ConversationEngine
      Schedule --> ReportGenerator
      
      PreProcessor --> PromptEngine
      ConversationEngine --> PromptEngine
      ReportGenerator --> PromptEngine
      
      PromptEngine --> LLM
      PreProcessor --> VectorModel
      ConversationEngine --> VectorModel
      
      %% å®‰å…¨å’Œæ€§èƒ½è¿æ¥
      ConversationEngine --> SecurityFilter
      SecurityFilter --> PerformanceManager
      PerformanceManager --> FallbackHandler
      
      %% å­˜å‚¨è¿æ¥
      PreProcessor --> SQLite
      PreProcessor --> ChromaDB
      ConversationEngine --> ChromaDB
      ConversationEngine --> SQLite
      ReportGenerator --> SQLite
      PerformanceManager --> Cache
      
      %% é…ç½®è¿æ¥
      PromptEngine --> TemplateLib
      SecurityFilter --> BlacklistLib
      AICore --> ConfigManager
      
      %% æ ·å¼å®šä¹‰
      style RSS fill:#e1f5fe
      style UserQuery fill:#f3e5f5
      style Schedule fill:#f3e5f5
      style LLM fill:#ffea00
      style VectorModel fill:#e3f2fd
      style PromptEngine fill:#fff3e0
      style SecurityFilter fill:#ffebee
      style FallbackHandler fill:#f1f8e9
      style SQLite fill:#e8f5e8
      style ChromaDB fill:#e8f5e8
      style Cache fill:#e8f5e8
  ```

### è¯¦ç»†å¤„ç†æµç¨‹

  ```mermaid
  graph LR
      subgraph Preprocessing ["ğŸ”„ é¢„å¤„ç†æµç¨‹"]
          A1["RSSå†…å®¹"] --> A2["æ‰¹é‡æå–10æ¡"]
          A2 --> A3["å¹¶è¡Œå¤„ç†"]
          A3 --> A4["LLMç”Ÿæˆæ ‡ç­¾æ‘˜è¦"]
          A3 --> A5["å‘é‡åŒ–768ç»´"]
          A4 --> A6["å­˜å‚¨SQLite"]
          A5 --> A7["å­˜å‚¨ChromaDB"]
      end
      
      subgraph Conversation ["ğŸ’¬ å¯¹è¯æµç¨‹"]
          B1["ç”¨æˆ·è¾“å…¥"] --> B2["å®‰å…¨è¿‡æ»¤"]
          B2 --> B3["å‘é‡åŒ–æŸ¥è¯¢"]
          B3 --> B4["æ£€ç´¢ç›¸å…³å†…å®¹"]
          B4 --> B5{"æ‰¾åˆ°å†…å®¹?"}
          B5 -->|æ˜¯| B6["ç”ŸæˆPrompt"]
          B5 -->|å¦| B7["å…œåº•è¯æœ¯"]
          B6 --> B8["LLMæ¨ç†"]
          B8 --> B9["ç»“æ„åŒ–è¾“å‡º"]
      end
      
      subgraph DailyReport ["ğŸ“° æ—¥æŠ¥æµç¨‹"]
          C1["å®šæ—¶6:30AM"] --> C2["èšåˆæ˜¨æ—¥å†…å®¹"]
          C2 --> C3{"å†…å®¹è¶³å¤Ÿ?"}
          C3 -->|æ˜¯| C4["ç”Ÿæˆæ—¥æŠ¥Prompt"]
          C3 -->|å¦| C5["è·³è¿‡ç”Ÿæˆ"]
          C4 --> C6["LLMç”Ÿæˆæ—¥æŠ¥"]
          C6 --> C7["å­˜å‚¨æ—¥æŠ¥"]
      end
      
      style A4 fill:#ffea00
      style A5 fill:#e3f2fd
      style B8 fill:#ffea00
      style B7 fill:#f1f8e9
      style C6 fill:#ffea00
      style C5 fill:#f1f8e9
  ```

### æŠ€æœ¯é€‰å‹

| ç»„ä»¶ | æŠ€æœ¯é€‰æ‹© | è¯´æ˜ |
|------|----------|------|
| **LLMæ¨¡å‹** | Qwen2.5-7B-Instruct | é€‚é…M1 MacBook Proï¼Œæ¨¡å‹å¤§å°çº¦4GBï¼ŒJSONç»“æ„è¾“å‡º |
| **å‘é‡æ¨¡å‹** | sentence-transformers | paraphrase-multilingual-MiniLM-L12-v2ï¼Œ768ç»´å‘é‡ |
| **å‘é‡æ•°æ®åº“** | ChromaDB | æœ¬åœ°åŒ–éƒ¨ç½²ï¼Œæ”¯æŒç›¸ä¼¼åº¦æœç´¢å’Œå…ƒæ•°æ®è¿‡æ»¤ |
| **æ ‡å‡†æ•°æ®åº“** | SQLite | å­˜å‚¨å®Œæ•´å†…å®¹ä¿¡æ¯ï¼Œæ”¯æŒAIç”Ÿæˆå­—æ®µ |
| **ç¼“å­˜ç³»ç»Ÿ** | Redis | å¯¹è¯ç¼“å­˜ã€ä¼šè¯çŠ¶æ€ç®¡ç†ï¼Œå¯é€‰ç»„ä»¶ |
| **é»‘åå•è¿‡æ»¤** | æ­£åˆ™è¡¨è¾¾å¼ + å…³é”®è¯åº“ | æ•æ„Ÿè¯æ£€æµ‹ã€Promptæ³¨å…¥æ”»å‡»é˜²æŠ¤ |
| **ä»»åŠ¡è°ƒåº¦** | APScheduler | ä¸ç°æœ‰è°ƒåº¦å™¨é›†æˆï¼Œæ”¯æŒAIå®šæ—¶ä»»åŠ¡ |
| **æ€§èƒ½ç›‘æ§** | è‡ªç ”è½»é‡çº§ç›‘æ§ | å“åº”æ—¶é—´è¿½è¸ªã€æ¨¡å‹è°ƒç”¨ç»Ÿè®¡ |

### æ•°æ®æµæ¶æ„

```mermaid
graph TB
    subgraph DataInput ["ğŸ“¥ æ•°æ®è¾“å…¥å±‚"]
        A[RSSå†…å®¹å…¥åº“] --> B[SQLiteå®Œæ•´å†…å®¹å­˜å‚¨]
        C[ç”¨æˆ·å¯¹è¯è¾“å…¥] --> D[è¾“å…¥éªŒè¯+é»‘åå•è¿‡æ»¤]
    end
    
    subgraph PreProcessFlow ["ğŸ”„ é¢„å¤„ç†æ•°æ®æµ"]
        B --> E[æ‰¹é‡å†…å®¹æå–<br/>10æ¡/æ‰¹æ¬¡]
        E --> F[å¹¶è¡Œå¤„ç†]
        F --> G[LLM: JSONç»“æ„è¾“å‡º<br/>tags/topics/summary]  
        F --> H[å‘é‡æ¨¡å‹: 768ç»´å‘é‡]
        G --> I[SQLite: æ›´æ–°AIå­—æ®µ]
        H --> J[ChromaDB: å­˜å‚¨å‘é‡+å…ƒæ•°æ®]
    end
    
    subgraph ConversationFlow ["ğŸ’¬ å¯¹è¯æ•°æ®æµ"]
        D --> K[ç”¨æˆ·è¾“å…¥å‘é‡åŒ–<br/>sentence-transformers]
        K --> L[ChromaDBå‘é‡æ£€ç´¢<br/>ç›¸ä¼¼åº¦åŒ¹é…]
        L --> M{æ£€ç´¢åˆ°å†…å®¹?}
        M -->|æ˜¯| N[SQLiteè·å–å®Œæ•´å†…å®¹<br/>åŸºäºcontent_ids]
        M -->|å¦| O[å·¥ç¨‹å…œåº•è¯æœ¯<br/>æ— LLMè°ƒç”¨]
        N --> P[åŠ¨æ€Promptç»„è£…<br/>ç»“æ„åŒ–JSONæ¨¡æ¿]
        P --> Q[LLMæ¨ç†<br/>JSONç»“æ„è¾“å‡º]
        Q --> R[å·¥ç¨‹è§£æ<br/>answer+references]
        R --> S[å‰ç«¯ç»“æ„åŒ–å±•ç¤º]
    end
    
    subgraph DailyReportFlow ["ğŸ“° æ—¥æŠ¥æ•°æ®æµ"]
        T[å®šæ—¶ä»»åŠ¡è§¦å‘<br/>6:30AM] --> U[SQLiteæŸ¥è¯¢<br/>ç”¨æˆ·æ˜¨æ—¥å…¨éƒ¨å†…å®¹] 
        U --> V{å†…å®¹å……è¶³?}
        V -->|æ˜¯| W[æ—¥æŠ¥Promptç»„è£…<br/>èšåˆæ¨¡æ¿]
        V -->|å¦| X[è·³è¿‡ç”Ÿæˆ<br/>å†…å®¹ä¸è¶³æé†’]
        W --> Y[LLMç”Ÿæˆæ—¥æŠ¥<br/>JSONç»“æ„è¾“å‡º]
        Y --> Z[æ—¥æŠ¥å­˜å‚¨<br/>SQLite]
    end
    
    subgraph CacheLayer ["âš¡ ç¼“å­˜å±‚"]
        Cache1[å¯¹è¯ç¼“å­˜<br/>Redis]
        Cache2[å‘é‡æ£€ç´¢ç¼“å­˜<br/>ChromaDBå†…ç½®]
        Cache3[ç”¨æˆ·ä¼šè¯çŠ¶æ€<br/>Redis]
    end
    
    subgraph ErrorHandling ["ğŸ›¡ï¸ å¼‚å¸¸å¤„ç†å±‚"]
        Error1[LLMè¶…æ—¶<br/>é™çº§åˆ°å†…å®¹åˆ—è¡¨]
        Error2[å‘é‡æ£€ç´¢å¤±è´¥<br/>å…œåº•è¯æœ¯]
        Error3[é¢„å¤„ç†å¤±è´¥<br/>é‡è¯•+åŸºç¡€æ ‡ç­¾]
    end
    
    %% ç¼“å­˜è¿æ¥
    K --> Cache1
    L --> Cache2
    D --> Cache3
    
    %% é”™è¯¯å¤„ç†è¿æ¥
    Q --> Error1
    L --> Error2
    G --> Error3
    
    %% æ ·å¼å®šä¹‰
    style A fill:#e1f5fe
    style C fill:#f3e5f5
    style T fill:#f3e5f5
    style G fill:#ffea00
    style H fill:#e3f2fd
    style K fill:#e3f2fd
    style Q fill:#ffea00
    style Y fill:#ffea00
    style O fill:#f1f8e9
    style X fill:#f1f8e9
    style Error1 fill:#ffebee
    style Error2 fill:#ffebee
    style Error3 fill:#ffebee
```

## ğŸ§  æ ¸å¿ƒç»„ä»¶è®¾è®¡

### 1. AIé¢„å¤„ç†æœåŠ¡

**åŠŸèƒ½**ï¼šå¯¹æ–°å…¥åº“çš„RSSå†…å®¹è¿›è¡Œæ™ºèƒ½é¢„å¤„ç†
**è°ƒç”¨åœºæ™¯**ï¼šé¢„å¤„ç†ï¼ˆå®šæ—¶è§¦å‘6:00AMï¼‰
**è¾“å‡ºæ ¼å¼**ï¼šJSONç»“æ„åŒ–æ•°æ®

```python
class AIPreprocessingService:
    async def daily_preprocessing_task(self):
        """æ¯æ—¥é¢„å¤„ç†ä»»åŠ¡"""
        # 1. è·å–å¾…å¤„ç†å†…å®¹ (æ‰¹é‡10æ¡)
        # 2. å¹¶è¡Œå¤„ç†ï¼šLLMç”Ÿæˆ+å‘é‡åŒ–
        # 3. LLMç”ŸæˆJSONæ ¼å¼æ ‡ç­¾/ä¸»é¢˜/æ‘˜è¦
        # 4. å‘é‡åŒ–å†…å®¹ (768ç»´)
        # 5. å­˜å‚¨åˆ°SQLiteå’ŒChromaDB
        # 6. å¼‚å¸¸å¤„ç†ï¼šé‡è¯•æœºåˆ¶+åŸºç¡€æ ‡ç­¾å…œåº•
        
    async def process_content_batch(self, contents: List[RSSContent]) -> List[ProcessedContent]:
        """æ‰¹é‡å¤„ç†å†…å®¹"""
        try:
            # å¹¶è¡Œè°ƒç”¨LLMå’Œå‘é‡æ¨¡å‹
            llm_results = await self.llm_service.generate_tags_summary_batch(contents)
            vectors = await self.vector_service.encode_batch([c.title + c.description for c in contents])
            
            return self._combine_results(contents, llm_results, vectors)
        except Exception as e:
            # å…œåº•ç­–ç•¥ï¼šåŸºç¡€è§„åˆ™ç”Ÿæˆæ ‡ç­¾
            return await self._fallback_processing(contents)
```

### 2. é»‘åå•è¿‡æ»¤æœåŠ¡

**åŠŸèƒ½**ï¼šå¤šå±‚å®‰å…¨é˜²æŠ¤ï¼Œé¿å…æ¶æ„åˆ©ç”¨
**è¿‡æ»¤å±‚çº§**ï¼šè¾“å…¥å±‚ã€å¤„ç†å±‚ã€è¾“å‡ºå±‚

```python
class BlacklistFilterService:
    def __init__(self):
        self.sensitive_patterns = self._load_sensitive_patterns()
        self.injection_patterns = self._load_injection_patterns()
    
    def filter_user_input(self, user_input: str) -> FilterResult:
        """ç”¨æˆ·è¾“å…¥è¿‡æ»¤"""
        # 1. æ•æ„Ÿè¯æ£€æµ‹
        # 2. Promptæ³¨å…¥æ”»å‡»æ£€æµ‹
        # 3. è¾“å…¥é•¿åº¦å’Œæ ¼å¼æ£€æŸ¥
        # 4. è¿”å›è¿‡æ»¤ç»“æœå’Œå»ºè®®
        
    def filter_llm_output(self, output: str, original_query: str) -> str:
        """LLMè¾“å‡ºè¿‡æ»¤"""
        # 1. æ•æ„Ÿå†…å®¹å®¡æŸ¥
        # 2. æ ¼å¼åŒ–è¾“å‡º
        # 3. å†…å®¹åˆè§„æ£€æŸ¥
```

### 3. åœºæ™¯åŒ–å‘é‡æ£€ç´¢æœåŠ¡

**åŠŸèƒ½**ï¼šæ ¹æ®ä¸åŒåœºæ™¯è¿›è¡Œæ™ºèƒ½å†…å®¹æ£€ç´¢
**æ”¯æŒåœºæ™¯**ï¼šå¯¹è¯æ£€ç´¢ã€æ—¥æŠ¥èšåˆ

```python
class VectorRetrievalService:
    async def retrieve_for_conversation(self, user_query: str, user_id: int) -> List[RetrievedContent]:
        """å¯¹è¯åœºæ™¯çš„å‘é‡æ£€ç´¢"""
        # 1. ç”¨æˆ·è¾“å…¥å‘é‡åŒ–
        query_vector = await self.embedder.encode(user_query)
        
        # 2. ChromaDBç›¸ä¼¼åº¦æ£€ç´¢ (ä»…è¯¥ç”¨æˆ·å†…å®¹)
        results = await self.chroma_client.query(
            query_embeddings=[query_vector],
            where={"user_id": user_id},
            n_results=5,
            include=['metadatas', 'distances']
        )
        
        # 3. ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤ (>0.6)
        # 4. SQLiteè·å–å®Œæ•´å†…å®¹ä¿¡æ¯
        return await self._build_retrieved_contents(results)
    
    async def retrieve_for_daily_report(self, user_id: int) -> List[RSSContent]:
        """æ—¥æŠ¥åœºæ™¯çš„å†…å®¹èšåˆ"""
        # è·å–ç”¨æˆ·æ˜¨æ—¥å…¨éƒ¨å†…å®¹ï¼ŒæŒ‰æ—¶é—´æ’åº
        yesterday = datetime.now() - timedelta(days=1)
        return await self.content_service.get_user_contents_by_date(user_id, yesterday)
```

### 4. Promptç”Ÿæˆå¼•æ“

**æ ¸å¿ƒè®¾è®¡**ï¼šç»Ÿä¸€çš„Promptç®¡ç†å™¨ï¼Œæ”¯æŒä¸‰ç§åœºæ™¯çš„æ¨¡æ¿ç”Ÿæˆå’ŒJSONç»“æ„åŒ–è¾“å‡º

```mermaid
graph TB
    subgraph PromptEngine ["âš™ï¸ Promptç”Ÿæˆå¼•æ“æ¶æ„"]
        Input["åœºæ™¯è¾“å…¥<br/>ç”¨æˆ·æŸ¥è¯¢+æ£€ç´¢å†…å®¹"]
        
        subgraph ScenarioRouter ["åœºæ™¯è·¯ç”±å™¨"]
            PreRoute["é¢„å¤„ç†åœºæ™¯"]
            ConvRoute["å¯¹è¯åœºæ™¯"] 
            ReportRoute["æ—¥æŠ¥åœºæ™¯"]
        end
        
        subgraph TemplateManager ["æ¨¡æ¿ç®¡ç†å™¨"]
            PreTemplate["é¢„å¤„ç†æ¨¡æ¿<br/>æ ‡ç­¾æ‘˜è¦ç”Ÿæˆ"]
            ConvTemplate["å¯¹è¯æ¨¡æ¿<br/>ç»“æ„åŒ–é—®ç­”"]
            ReportTemplate["æ—¥æŠ¥æ¨¡æ¿<br/>å†…å®¹èšåˆ"]
        end
        
        subgraph OutputFormatter ["è¾“å‡ºæ ¼å¼åŒ–å™¨"]
            JSONValidator["JSONæ ¼å¼éªŒè¯"]
            StructureBuilder["ç»“æ„åŒ–æ„å»ºå™¨"]
        end
        
        Output["JSONç»“æ„è¾“å‡º<br/>å‘é€è‡³LLM"]
        
        Input --> ScenarioRouter
        PreRoute --> PreTemplate
        ConvRoute --> ConvTemplate
        ReportRoute --> ReportTemplate
        
        PreTemplate --> OutputFormatter
        ConvTemplate --> OutputFormatter
        ReportTemplate --> OutputFormatter
        
        JSONValidator --> StructureBuilder
        StructureBuilder --> Output
        
        style Input fill:#e1f5fe
        style Output fill:#ffea00
        style JSONValidator fill:#f1f8e9
    end
```

#### åœºæ™¯åŒ–æ¨¡æ¿è®¾è®¡

| åœºæ™¯ | è§¦å‘æ–¹å¼ | è¾“å…¥æ•°æ® | è¾“å‡ºæ ¼å¼ | ç¤ºä¾‹ç”¨é€” |
|------|----------|----------|----------|----------|
| **é¢„å¤„ç†** | å®šæ—¶6:00AM | RSSåŸå§‹å†…å®¹ | `{"tags": [], "topics": [], "summary": ""}` | å†…å®¹æ™ºèƒ½æ ‡è®° |
| **å¯¹è¯** | ç”¨æˆ·æŸ¥è¯¢ | ç”¨æˆ·é—®é¢˜+æ£€ç´¢å†…å®¹ | `{"answer": "", "references": []}` | æ™ºèƒ½é—®ç­” |
| **æ—¥æŠ¥** | å®šæ—¶6:30AM | ç”¨æˆ·æ˜¨æ—¥å†…å®¹ | `{"title": "", "content": "", "highlights": []}` | å†…å®¹èšåˆ |

#### æ ¸å¿ƒå®ç°ä»£ç 

```python
class UnifiedPromptEngine:
    """ç»Ÿä¸€çš„Promptç”Ÿæˆå¼•æ“ï¼Œç®¡ç†ä¸‰ç§åœºæ™¯çš„æ¨¡æ¿ç”Ÿæˆ"""
    
    def __init__(self):
        self.template_manager = TemplateManager()
        self.scenario_router = ScenarioRouter()
        self.output_formatter = OutputFormatter()
    
    async def generate_prompt(self, scenario: str, **kwargs) -> Optional[str]:
        """ç»Ÿä¸€çš„Promptç”Ÿæˆå…¥å£"""
        
        # 1. åœºæ™¯è·¯ç”±
        scenario_type = self.scenario_router.route(scenario, **kwargs)
        if not scenario_type:
            return None
            
        # 2. æ¨¡æ¿é€‰æ‹©å’Œç”Ÿæˆ
        template = await self.template_manager.get_template(scenario_type)
        raw_prompt = template.format(**kwargs)
        
        # 3. JSONæ ¼å¼åŒ–å’ŒéªŒè¯
        structured_prompt = self.output_formatter.format_json_prompt(
            raw_prompt, scenario_type
        )
        
        return structured_prompt
    
    # åœºæ™¯ç‰¹å®šæ–¹æ³•
    async def generate_preprocessing_prompt(self, content: RSSContent) -> str:
        """é¢„å¤„ç†åœºæ™¯ï¼šç”Ÿæˆå†…å®¹æ ‡ç­¾å’Œæ‘˜è¦"""
        return await self.generate_prompt("preprocessing", content=content)
    
    async def generate_conversation_prompt(self, user_query: str, contents: List[RetrievedContent]) -> Optional[str]:
        """å¯¹è¯åœºæ™¯ï¼šåŸºäºæ£€ç´¢å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜"""
        if not contents:
            return None  # æ— å†…å®¹æ—¶ä¸ç”ŸæˆPromptï¼Œç”±å·¥ç¨‹å…œåº•
            
        return await self.generate_prompt(
            "conversation", 
            user_query=user_query, 
            retrieved_contents=contents
        )
    
    async def generate_daily_report_prompt(self, user_contents: List[RSSContent], date: str) -> str:
        """æ—¥æŠ¥åœºæ™¯ï¼šèšåˆç”¨æˆ·å†…å®¹ç”Ÿæˆæ—¥æŠ¥"""
        return await self.generate_prompt(
            "daily_report",
            contents=user_contents,
            date=date
        )

class TemplateManager:
    """æ¨¡æ¿ç®¡ç†å™¨ï¼šè´Ÿè´£å„åœºæ™¯çš„æ¨¡æ¿ç®¡ç†"""
    
    PREPROCESSING_TEMPLATE = '''
    è¯·åˆ†æä»¥ä¸‹RSSå†…å®¹ï¼Œç”Ÿæˆæ ‡ç­¾ã€ä¸»é¢˜å’Œæ‘˜è¦ï¼Œä¸¥æ ¼æŒ‰JSONæ ¼å¼è¿”å›ï¼š
    
    æ ‡é¢˜ï¼š{title}
    å†…å®¹ï¼š{description}
    
    è¿”å›æ ¼å¼ï¼š
    {{
        "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3"],
        "topics": ["ä¸»é¢˜1", "ä¸»é¢˜2"], 
        "summary": "ç®€æ´çš„å†…å®¹æ‘˜è¦...",
        "content_type": "video|article|news"
    }}
    '''
    
    CONVERSATION_TEMPLATE = '''
    åŸºäºç”¨æˆ·è®¢é˜…çš„ä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜ï¼Œå¿…é¡»è¿”å›JSONæ ¼å¼ï¼š
    
    ç”¨æˆ·é—®é¢˜ï¼š{user_query}
    
    ç›¸å…³å†…å®¹ï¼š
    {content_list}
    
    è¿”å›æ ¼å¼ï¼š
    {{
        "answer": "åŸºäºæ‚¨çš„è®¢é˜…å†…å®¹çš„è¯¦ç»†å›ç­”...",
        "references": [
            {{"content_id": 123, "title": "å†…å®¹æ ‡é¢˜", "snippet": "ç›¸å…³ç‰‡æ®µ", "relevance": 0.9}}
        ],
        "confidence": 0.8,
        "suggestion": "è¿›ä¸€æ­¥çš„å»ºè®®æˆ–ç›¸å…³è¯é¢˜"
    }}
    '''
    
    DAILY_REPORT_TEMPLATE = '''
    åŸºäºç”¨æˆ·{date}çš„è®¢é˜…å†…å®¹ï¼Œç”Ÿæˆä¸ªæ€§åŒ–æ—¥æŠ¥ï¼š
    
    å†…å®¹åˆ—è¡¨ï¼š
    {content_summary}
    
    è¿”å›æ ¼å¼ï¼š
    {{
        "title": "ğŸ“° {date} ä¸ªäººèµ„è®¯æ—¥æŠ¥",
        "content": "## ä»Šæ—¥è¦é—»\n\nè¯¦ç»†çš„æ—¥æŠ¥å†…å®¹...",
        "highlights": ["é‡ç‚¹1", "é‡ç‚¹2", "é‡ç‚¹3"],
        "main_topics": ["ä¸»è¦è¯é¢˜1", "ä¸»è¦è¯é¢˜2"],
        "content_count": {content_count},
        "reading_time": "é¢„è®¡é˜…è¯»æ—¶é—´5åˆ†é’Ÿ"
    }}
    '''
```

### 5. å¼‚å¸¸å¤„ç†å’Œå…œåº•æœºåˆ¶

**åŠŸèƒ½**ï¼šç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§å’Œç”¨æˆ·ä½“éªŒ

```python
class FallbackHandler:
    async def handle_no_content_found(self, user_query: str, user_id: int) -> ConversationResponse:
        """å¤„ç†æ£€ç´¢ä¸åˆ°å†…å®¹çš„æƒ…å†µ"""
        # 1. åˆ†æç”¨æˆ·å†å²åå¥½
        user_tags = await self.get_user_frequent_tags(user_id)
        
        # 2. ç”Ÿæˆæ™ºèƒ½å»ºè®®
        suggestions = self._generate_content_suggestions(user_query, user_tags)
        
        return ConversationResponse(
            success=True,
            answer=f"æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚{suggestions}",
            is_fallback=True
        )
    
    async def handle_llm_timeout(self, retrieved_contents: List[RetrievedContent]) -> ConversationResponse:
        """å¤„ç†LLMè¶…æ—¶çš„é™çº§ç­–ç•¥"""
        # é™çº§åˆ°ç®€å•çš„å†…å®¹åˆ—è¡¨å±•ç¤º
        return ConversationResponse(
            success=True,
            answer="æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œä½†AIåˆ†æè¶…æ—¶ï¼Œä¸ºæ‚¨å±•ç¤ºç›¸å…³å†…å®¹åˆ—è¡¨ï¼š",
            content_list=retrieved_contents,
            is_degraded=True
        )
```



## ğŸ“Š APIæ¥å£è®¾è®¡

### æ•°æ®æ¨¡å‹å®šä¹‰

```python
from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime

class ConversationRequest(BaseModel):
    query: str                           # ç”¨æˆ·è¾“å…¥æŸ¥è¯¢
    user_id: int                         # ç”¨æˆ·ID
    enable_cross_user: bool = False      # æ˜¯å¦å¼€å¯è·¨ç”¨æˆ·æ¨è(æš‚æ—¶ä¸å®ç°)

class ContentReference(BaseModel):
    content_id: int                      # å†…å®¹ID
    title: str                           # å†…å®¹æ ‡é¢˜
    url: str                             # å†…å®¹é“¾æ¥
    platform: str                        # å¹³å°æ¥æº
    snippet: str                         # å¼•ç”¨ç‰‡æ®µ
    relevance_score: float               # ç›¸å…³åº¦åˆ†æ•°

class ConversationResponse(BaseModel):
    success: bool                        # è¯·æ±‚æ˜¯å¦æˆåŠŸ
    answer: str                          # AIç”Ÿæˆçš„å›ç­”æ–‡æœ¬
    referenced_contents: List[ContentReference] = []  # å¼•ç”¨çš„å†…å®¹åˆ—è¡¨
    has_links: bool                      # æ˜¯å¦åŒ…å«é“¾æ¥
    response_type: str                   # å“åº”ç±»å‹: "ai_generated" | "fallback" | "degraded"
    processing_time: float               # å¤„ç†æ—¶é—´(æ¯«ç§’)
    is_cached: bool = False              # æ˜¯å¦æ¥è‡ªç¼“å­˜

class DailyReportResponse(BaseModel):
    success: bool                        # ç”Ÿæˆæ˜¯å¦æˆåŠŸ
    date: str                            # æ—¥æŠ¥æ—¥æœŸ "2024-12-19"
    content: str                         # æ—¥æŠ¥å†…å®¹(Markdownæ ¼å¼)
    content_count: int                   # èšåˆçš„å†…å®¹æ•°é‡
    generated_at: datetime               # ç”Ÿæˆæ—¶é—´
    topics: List[str] = []               # ä¸»è¦è¯é¢˜
```

### å¯¹è¯æ¥å£

```python
@router.post("/api/v1/ai/conversation")
async def ai_conversation(request: ConversationRequest):
    """AIæ™ºèƒ½å¯¹è¯æ¥å£ - å®Œå…¨å·¥ç¨‹ä¾§åŒ…è£…ï¼Œç”¨æˆ·ä¸ç›´æ¥ä¸LLMäº¤äº’"""
    
    try:
        # Step 1: è¾“å…¥éªŒè¯å’Œé»‘åå•è¿‡æ»¤
        filter_result = blacklist_service.filter_user_input(request.query)
        if not filter_result.is_safe:
            return ConversationResponse(
                success=False,
                answer="è¾“å…¥å†…å®¹åŒ…å«ä¸å½“ä¿¡æ¯ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚",
                response_type="blocked"
            )
        
        # Step 2: ç”¨æˆ·è¾“å…¥å‘é‡åŒ–
        query_vector = await embedding_service.encode(request.query)
        
        # Step 3: å‘é‡æ£€ç´¢ç›¸å…³å†…å®¹
        retrieved_contents = await vector_service.retrieve_for_conversation(
            user_query=request.query,
            user_id=request.user_id
        )
        
        # Step 4: æ£€æŸ¥æ˜¯å¦æœ‰ç›¸å…³å†…å®¹
        if not retrieved_contents:
            # å·¥ç¨‹å…œåº•ç­–ç•¥ï¼Œä¸è°ƒç”¨LLM
            fallback_message = await fallback_handler.handle_no_content_found(
                request.query, request.user_id
            )
            return ConversationResponse(
                success=True,
                answer=fallback_message,
                response_type="fallback"
            )
        
        # Step 5: ç”Ÿæˆç»“æ„åŒ–Prompt
        prompt = await prompt_engine.generate_conversation_prompt(
            request.query, retrieved_contents
        )
        
        # Step 6: LLMæ¨ç† (JSONç»“æ„åŒ–è¾“å‡º)
        try:
            llm_response = await llm_service.generate_with_timeout(
                prompt=prompt,
                timeout_seconds=10,
                response_format="json"
            )
            
            # Step 7: è§£æLLMçš„JSONè¾“å‡º
            parsed_response = json.loads(llm_response)
            
            # Step 8: å·¥ç¨‹ä¾§åŒ…è£…æœ€ç»ˆå“åº”
            return ConversationResponse(
                success=True,
                answer=parsed_response["answer"],
                referenced_contents=[
                    ContentReference(**ref) for ref in parsed_response.get("references", [])
                ],
                has_links=len(parsed_response.get("references", [])) > 0,
                response_type="ai_generated",
                processing_time=response_time
            )
            
        except asyncio.TimeoutError:
            # LLMè¶…æ—¶ï¼Œé™çº§å¤„ç†
            return await fallback_handler.handle_llm_timeout(retrieved_contents)
            
    except Exception as e:
        logger.error(f"AIå¯¹è¯æœåŠ¡å¼‚å¸¸: {e}")
        return ConversationResponse(
            success=False,
            answer="æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚",
            response_type="error"
        )
```

### æ—¥æŠ¥æ¥å£

```python
@router.get("/api/v1/ai/daily-report/{user_id}/{date}")
async def get_daily_report(user_id: int, date: str):
    """è·å–ç”¨æˆ·æ¯æ—¥AIæŠ¥å‘Š"""
    
    try:
        # Step 1: éªŒè¯æ—¥æœŸæ ¼å¼å’Œç”¨æˆ·æƒé™
        report_date = datetime.strptime(date, "%Y-%m-%d").date()
        
        # Step 2: è·å–ç”¨æˆ·å½“æ—¥å†…å®¹
        user_contents = await content_service.get_user_contents_by_date(
            user_id=user_id,
            target_date=report_date
        )
        
        # Step 3: æ£€æŸ¥å†…å®¹æ•°é‡æ˜¯å¦è¶³å¤Ÿç”Ÿæˆæ—¥æŠ¥
        if len(user_contents) < 3:
            return DailyReportResponse(
                success=True,
                date=date,
                content="ğŸ“° ä»Šæ—¥å†…å®¹è¾ƒå°‘ï¼Œæš‚æœªç”ŸæˆAIæ—¥æŠ¥ã€‚\n\nå»ºè®®æ£€æŸ¥è®¢é˜…é…ç½®æˆ–æ‰‹åŠ¨æ‹‰å–å†…å®¹ã€‚",
                content_count=len(user_contents),
                generated_at=datetime.now(),
                response_type="insufficient_content"
            )
        
        # Step 4: ç”Ÿæˆæ—¥æŠ¥Prompt
        prompt = await prompt_engine.generate_daily_report_prompt(
            user_contents=user_contents,
            user_id=user_id,
            date=date
        )
        
        # Step 5: LLMç”Ÿæˆæ—¥æŠ¥ (JSONç»“æ„åŒ–è¾“å‡º)
        llm_response = await llm_service.generate_daily_report(
            prompt=prompt,
            response_format="json"
        )
        
        parsed_report = json.loads(llm_response)
        
        return DailyReportResponse(
            success=True,
            date=date,
            content=parsed_report["content"],
            content_count=len(user_contents),
            generated_at=datetime.now(),
            topics=parsed_report.get("main_topics", [])
        )
        
    except Exception as e:
        logger.error(f"æ—¥æŠ¥ç”Ÿæˆå¼‚å¸¸: {e}")
        return DailyReportResponse(
            success=False,
            date=date,
            content="æ—¥æŠ¥ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚",
            content_count=0,
            generated_at=datetime.now()
        )
```

### æ€§èƒ½ç›‘æ§æ¥å£

```python
@router.get("/api/v1/ai/metrics")
async def get_ai_metrics():
    """è·å–AIæœåŠ¡æ€§èƒ½æŒ‡æ ‡"""
    return {
        "llm_model_status": "healthy",           # LLMæ¨¡å‹çŠ¶æ€
        "average_response_time": 1.2,           # å¹³å‡å“åº”æ—¶é—´(ç§’)
        "daily_conversation_count": 156,        # ä»Šæ—¥å¯¹è¯æ¬¡æ•°
        "cache_hit_rate": 0.35,                 # ç¼“å­˜å‘½ä¸­ç‡
        "fallback_rate": 0.08,                  # å…œåº•å“åº”æ¯”ä¾‹
        "vector_db_size": "2.1GB",              # å‘é‡æ•°æ®åº“å¤§å°
        "preprocessing_queue": 23               # é¢„å¤„ç†é˜Ÿåˆ—é•¿åº¦
    }
```

## âš™ï¸ é…ç½®ç®¡ç†

```python
AI_CONFIG = {
    "llm": {
        "model_name": "Qwen/Qwen2.5-7B-Instruct",
        "model_path": "./models/qwen2.5-7b-instruct",  # æœ¬åœ°æ¨¡å‹è·¯å¾„
        "max_tokens": 2048,
        "temperature": 0.7,
        "timeout_seconds": 10,                          # LLMæ¨ç†è¶…æ—¶æ—¶é—´
        "max_concurrent_requests": 3,                   # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
        "response_format": "json"                       # å¼ºåˆ¶JSONè¾“å‡ºæ ¼å¼
    },
    "embedding": {
        "model_name": "paraphrase-multilingual-MiniLM-L12-v2",
        "vector_dimension": 768,
        "batch_size": 32,                               # å‘é‡åŒ–æ‰¹å¤„ç†å¤§å°
        "normalize_embeddings": True                    # æ˜¯å¦å½’ä¸€åŒ–å‘é‡
    },
    "vector_db": {
        "chroma_persist_directory": "./data/chroma_db", # ChromaDBå­˜å‚¨è·¯å¾„
        "collection_name": "rss_contents",              # é›†åˆåç§°
        "similarity_threshold": 0.6,                    # ç›¸ä¼¼åº¦é˜ˆå€¼
        "max_results": 5                                # æœ€å¤§æ£€ç´¢ç»“æœæ•°
    },
    "preprocessing": {
        "schedule": "0 6 * * *",                        # æ¯æ—¥6:00AM
        "batch_size": 10,                               # æ‰¹å¤„ç†å¤§å°
        "max_retries": 3,                               # æœ€å¤§é‡è¯•æ¬¡æ•°
        "retry_delay": 60,                              # é‡è¯•å»¶è¿Ÿ(ç§’)
        "fallback_tags": ["å†…å®¹", "ä¿¡æ¯", "èµ„è®¯"]        # å…œåº•æ ‡ç­¾
    },
    "daily_report": {
        "schedule": "30 6 * * *",                       # æ¯æ—¥6:30AM
        "min_content_count": 3,                         # æœ€å°‘å†…å®¹æ•°é‡
        "max_content_count": 50,                        # æœ€å¤šå†…å®¹æ•°é‡
        "report_format": "markdown"                     # æ—¥æŠ¥æ ¼å¼
    },
    "conversation": {
        "max_query_length": 500,                        # æœ€å¤§æŸ¥è¯¢é•¿åº¦
        "cache_ttl": 3600,                              # ç¼“å­˜ç”Ÿå­˜æ—¶é—´(ç§’)
        "enable_cache": True,                           # æ˜¯å¦å¯ç”¨ç¼“å­˜
        "fallback_messages": {                          # å…œåº•è¯æœ¯é…ç½®
            "no_content": "æŠ±æ­‰ï¼Œåœ¨æ‚¨çš„è®¢é˜…å†…å®¹ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚å»ºè®®æ‚¨ï¼š\n1. å°è¯•å…¶ä»–å…³é”®è¯\n2. æ£€æŸ¥è®¢é˜…é…ç½®\n3. æ‰‹åŠ¨æ‹‰å–æœ€æ–°å†…å®¹",
            "timeout": "AIåˆ†æè¶…æ—¶ï¼Œä¸ºæ‚¨å±•ç¤ºç›¸å…³å†…å®¹åˆ—è¡¨ï¼š",
            "error": "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        }
    },
    "security": {
        "enable_blacklist": True,                       # å¯ç”¨é»‘åå•è¿‡æ»¤
        "blacklist_file": "./config/blacklist.json",   # é»‘åå•æ–‡ä»¶è·¯å¾„
        "max_requests_per_minute": 30,                  # æ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ•°
        "enable_rate_limit": True                       # å¯ç”¨é™æµ
    },
    "performance": {
        "enable_monitoring": True,                      # å¯ç”¨æ€§èƒ½ç›‘æ§
        "log_slow_queries": True,                       # è®°å½•æ…¢æŸ¥è¯¢
        "slow_query_threshold": 2.0,                    # æ…¢æŸ¥è¯¢é˜ˆå€¼(ç§’)
        "metrics_collection_interval": 300             # æŒ‡æ ‡æ”¶é›†é—´éš”(ç§’)
    }
}
```

### é»‘åå•é…ç½®æ–‡ä»¶ç¤ºä¾‹

```json
// config/blacklist.json
{
    "sensitive_keywords": [
        "æ”¿æ²»æ•æ„Ÿè¯",
        "æš´åŠ›å†…å®¹",
        "è‰²æƒ…å†…å®¹"
    ],
    "injection_patterns": [
        "ignore.*previous.*instructions",
        "forget.*system.*prompt",
        "ä½ æ˜¯.*åŠ©æ‰‹.*ç°åœ¨.*æ‰®æ¼”",
        "è¯·å¿˜è®°.*ä¹‹å‰.*è§„åˆ™"
    ],
    "blocked_domains": [
        "malicious-site.com"
    ]
}
```

## ğŸ”§ ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ

### è°ƒåº¦å™¨é›†æˆ

```python
# app/main.py
class AIScheduler:
    def __init__(self):
        self.scheduler = AsyncIOScheduler()
        self.preprocessing_service = AIPreprocessingService()
        self.report_service = DailyReportService()
    
    def setup_jobs(self):
        """è®¾ç½®AIç›¸å…³å®šæ—¶ä»»åŠ¡"""
        # AIé¢„å¤„ç†ä»»åŠ¡
        self.scheduler.add_job(
            self.preprocessing_service.daily_preprocessing_task,
            'cron', hour=6, minute=0
        )
        
        # æ—¥æŠ¥ç”Ÿæˆä»»åŠ¡
        self.scheduler.add_job(
            self.report_service.generate_all_user_reports,
            'cron', hour=6, minute=30
        )

# åœ¨main.pyä¸­é›†æˆ
ai_scheduler = AIScheduler()
ai_scheduler.setup_jobs()
```

### å‰ç«¯é›†æˆ

ç°æœ‰çš„å¯¹è¯å¡ç‰‡ç»„ä»¶å·²ç»å‡†å¤‡å°±ç»ªï¼Œåªéœ€è¦è¿æ¥åç«¯APIï¼š

```typescript
// å‰ç«¯è°ƒç”¨ç¤ºä¾‹
const response = await fetch('/api/v1/ai/conversation', {
  method: 'POST',
  body: JSON.stringify({ question: userInput })
});
```

## ğŸ¯ å®æ–½è®¡åˆ’

### Phase 1: åŸºç¡€AIé¢„å¤„ç† (Week 1-2)
- [ ] æœ¬åœ°LLMæœåŠ¡éƒ¨ç½² (Qwen2.5-7B)
- [ ] å‘é‡åŒ–æœåŠ¡å®ç° (sentence-transformers)
- [ ] ChromaDBå‘é‡æ•°æ®åº“é›†æˆ
- [ ] åŸºç¡€é¢„å¤„ç†è°ƒåº¦å™¨
- [ ] é‡è¯•æœºåˆ¶å’Œå…œåº•ç­–ç•¥

### Phase 2: æ„å›¾è¯†åˆ«ä¸è¿‡æ»¤ (Week 3)
- [ ] å…³é”®è¯æ­£åˆ™æ„å›¾è¯†åˆ«
- [ ] é»‘åå•è¿‡æ»¤å™¨å®ç°
- [ ] åŸºç¡€å®‰å…¨é˜²æŠ¤æµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•

### Phase 3: Promptç”Ÿæˆå¼•æ“ (Week 4)
- [ ] å‘é‡åº“åœˆé€‰è§„åˆ™å®ç°
- [ ] Promptæ¨¡æ¿åº“å»ºè®¾
- [ ] åŠ¨æ€Promptç»„è£…å™¨
- [ ] ä¸‰ç§åœºæ™¯æ¨¡æ¿éªŒè¯

### Phase 4: å¯¹è¯ä¸æ—¥æŠ¥æœåŠ¡ (Week 5-6)
- [ ] å¯¹è¯APIæ¥å£å¼€å‘
- [ ] æ—¥æŠ¥ç”ŸæˆæœåŠ¡å®ç°
- [ ] è¾“å‡ºè¿‡æ»¤ä¼˜åŒ–
- [ ] å‰ç«¯é›†æˆæµ‹è¯•

### Phase 5: ç›‘æ§ä¸ä¼˜åŒ– (Week 7)
- [ ] æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
- [ ] ç”¨æˆ·åé¦ˆæ”¶é›†
- [ ] æ¨¡å‹æ•ˆæœä¼˜åŒ–
- [ ] ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### æ€§èƒ½æŒ‡æ ‡
- **æ„å›¾è¯†åˆ«å‡†ç¡®ç‡**: >85% (æ­£åˆ™å®ç°)
- **å†…å®¹æ£€ç´¢ç›¸å…³æ€§**: >80% (å‘é‡ç›¸ä¼¼åº¦)
- **ç³»ç»Ÿå“åº”æ—¶é—´**: <2ç§’ (å¯¹è¯), <30ç§’ (æ—¥æŠ¥)

### å®‰å…¨æŒ‡æ ‡
- **é»‘åå•æ‹¦æˆªç‡**: >99%
- **å†…å®¹èŒƒå›´æ§åˆ¶**: 100% (ä»…åŸºäºç”¨æˆ·è®¢é˜…)

### ç”¨æˆ·ä½“éªŒæŒ‡æ ‡
- **å¯¹è¯æˆåŠŸç‡**: >90%
- **æ—¥æŠ¥é˜…è¯»å®Œæˆç‡**: >70%

## ğŸ”„ åç»­ä¼˜åŒ–æ–¹å‘

### çŸ­æœŸä¼˜åŒ– (1-3ä¸ªæœˆ)
- BERTæ„å›¾è¯†åˆ«å‡çº§
- ç”¨æˆ·åé¦ˆæœºåˆ¶
- æ¨¡æ¿ä¸ªæ€§åŒ–æ”¯æŒ

### ä¸­æœŸæ‹“å±• (3-6ä¸ªæœˆ)
- å¤šæ¨¡æ€å†…å®¹æ”¯æŒ
- æ™ºèƒ½æ¨èç³»ç»Ÿ
- å†…å®¹èšç±»åˆ†æ

### é•¿æœŸæ„¿æ™¯ (6-12ä¸ªæœˆ)
- æ¨¡å‹å¾®è°ƒ
- çŸ¥è¯†å›¾è°±æ„å»º
- å®æ—¶åˆ†æèƒ½åŠ›

---

**æ–‡æ¡£çŠ¶æ€**: è®¾è®¡å®Œæˆï¼Œå‡†å¤‡å¼€å§‹å®æ–½  
**ä¸‹ä¸€æ­¥**: å¼€å§‹Phase 1çš„åŸºç¡€AIé¢„å¤„ç†åŠŸèƒ½å¼€å‘