#!/usr/bin/env python3
"""
å­—æ®µæ ‡å‡†åŒ–æ£€æŸ¥å’Œä¿®å¤å·¥å…·
è¯†åˆ«å¹¶ä¿®å¤é¡¹ç›®ä¸­çš„å­—æ®µå‘½åä¸ä¸€è‡´é—®é¢˜
"""

import os
import re
import json
import sqlite3
from pathlib import Path
from typing import Dict, List, Set, Tuple
from dataclasses import dataclass


@dataclass
class FieldIssue:
    """å­—æ®µé—®é¢˜è®°å½•"""
    file_path: str
    line_number: int
    issue_type: str
    current_field: str
    suggested_field: str
    context: str


class FieldStandardizationChecker:
    """å­—æ®µæ ‡å‡†åŒ–æ£€æŸ¥å™¨"""
    
    def __init__(self, root_path: str = "."):
        self.root_path = Path(root_path)
        self.issues: List[FieldIssue] = []
        
        # å®šä¹‰æ ‡å‡†å­—æ®µæ˜ å°„
        self.field_standards = {
            # æ¨¡ç‰ˆç›¸å…³
            "id": "template_id",  # JSONé…ç½®ä¸­çš„idåº”è¯¥å«template_id
            "display_name": "template_name",  # æ¨¡ç‰ˆæ˜¾ç¤ºåç§°ç»Ÿä¸€
            "name": "template_name",  # å„ç§nameéƒ½ç»Ÿä¸€ä¸ºtemplate_name
            
            # ç”¨æˆ·ç›¸å…³
            "user_id": "user_id",  # ä¿æŒä¸å˜
            "username": "username",  # ä¿æŒä¸å˜
            
            # è®¢é˜…ç›¸å…³ 
            "subscription_id": "subscription_id",  # ä¿æŒä¸å˜
            "source_id": "template_id",  # å‰ç«¯çš„source_idæ”¹ä¸ºtemplate_id
            
            # çŠ¶æ€ç›¸å…³
            "status": "status",  # ä¿æŒä¸å˜ï¼Œä½†å€¼éœ€è¦ç»Ÿä¸€
            "is_active": "is_active",  # ä¿æŒä¸å˜
            
            # æ—¶é—´ç›¸å…³
            "created_at": "created_at",  # ç»Ÿä¸€æ—¶é—´å­—æ®µå
            "create_time": "created_at",  # ç»Ÿä¸€ä¸ºcreated_at
            "updated_at": "updated_at",  # ç»Ÿä¸€æ—¶é—´å­—æ®µå
            "update_time": "updated_at"  # ç»Ÿä¸€ä¸ºupdated_at
        }
        
        # çŠ¶æ€å€¼æ ‡å‡†åŒ–
        self.status_standards = {
            "open": "active",
            "closed": "inactive", 
            "active": "active",
            "inactive": "inactive",
            "error": "error"
        }
        
        # éœ€è¦æ£€æŸ¥çš„æ–‡ä»¶æ¨¡å¼
        self.file_patterns = [
            "**/*.py",
            "**/*.json",
            "**/*.ts",
            "**/*.tsx"
        ]
        
        # æ’é™¤çš„ç›®å½•
        self.exclude_dirs = {
            "__pycache__", ".git", "node_modules", ".next", 
            "venv", ".venv", "dist", "build"
        }
    
    def check_all_files(self) -> List[FieldIssue]:
        """æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶çš„å­—æ®µæ ‡å‡†åŒ–é—®é¢˜"""
        print("ğŸ” å¼€å§‹æ£€æŸ¥å­—æ®µæ ‡å‡†åŒ–é—®é¢˜...")
        
        for pattern in self.file_patterns:
            for file_path in self.root_path.glob(pattern):
                if self._should_skip_file(file_path):
                    continue
                
                try:
                    self._check_file(file_path)
                except Exception as e:
                    print(f"âŒ æ£€æŸ¥æ–‡ä»¶å¤±è´¥: {file_path} - {e}")
        
        return self.issues
    
    def _should_skip_file(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡è¿™ä¸ªæ–‡ä»¶"""
        # è·³è¿‡æ’é™¤çš„ç›®å½•
        for part in file_path.parts:
            if part in self.exclude_dirs:
                return True
        
        # è·³è¿‡è¿™ä¸ªå·¥å…·æœ¬èº«
        if file_path.name == "field_standardization_checker.py":
            return True
            
        return False
    
    def _check_file(self, file_path: Path) -> None:
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if file_path.suffix == '.json':
                self._check_json_file(file_path, content)
            elif file_path.suffix in ['.py', '.ts', '.tsx']:
                self._check_code_file(file_path, content)
                
        except UnicodeDecodeError:
            # è·³è¿‡äºŒè¿›åˆ¶æ–‡ä»¶
            pass
    
    def _check_json_file(self, file_path: Path, content: str) -> None:
        """æ£€æŸ¥JSONæ–‡ä»¶"""
        try:
            data = json.loads(content)
            self._check_json_data(file_path, data, content)
        except json.JSONDecodeError:
            pass
    
    def _check_json_data(self, file_path: Path, data: any, content: str) -> None:
        """é€’å½’æ£€æŸ¥JSONæ•°æ®"""
        if isinstance(data, dict):
            for key, value in data.items():
                # æ£€æŸ¥å­—æ®µå
                if key in self.field_standards and key != self.field_standards[key]:
                    line_num = self._find_line_number(content, f'"{key}":')
                    self.issues.append(FieldIssue(
                        file_path=str(file_path),
                        line_number=line_num,
                        issue_type="field_name",
                        current_field=key,
                        suggested_field=self.field_standards[key],
                        context=f'JSON field "{key}" should be "{self.field_standards[key]}"'
                    ))
                
                # é€’å½’æ£€æŸ¥åµŒå¥—ç»“æ„
                self._check_json_data(file_path, value, content)
                
        elif isinstance(data, list):
            for item in data:
                self._check_json_data(file_path, item, content)
    
    def _check_code_file(self, file_path: Path, content: str) -> None:
        """æ£€æŸ¥ä»£ç æ–‡ä»¶"""
        lines = content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            # æ£€æŸ¥å­—æ®µå®šä¹‰å’Œä½¿ç”¨
            self._check_line_for_field_issues(file_path, line_num, line)
    
    def _check_line_for_field_issues(self, file_path: Path, line_num: int, line: str) -> None:
        """æ£€æŸ¥å•è¡Œä»£ç çš„å­—æ®µé—®é¢˜"""
        # æ£€æŸ¥å­—å…¸é”®çš„ä½¿ç”¨ å¦‚ "source_id", 'display_name' ç­‰
        field_patterns = [
            r'["\'](\w+)["\']:\s*',  # JSONé£æ ¼çš„é”®
            r'\.(\w+)\s*=',  # å±æ€§èµ‹å€¼
            r'(\w+)\s*=\s*Field',  # Pydanticå­—æ®µå®šä¹‰
            r'item\.(\w+)',  # å¯¹è±¡å±æ€§è®¿é—®
            r'\.(\w+)\s*\?',  # TypeScriptå¯é€‰å±æ€§
        ]
        
        for pattern in field_patterns:
            matches = re.finditer(pattern, line)
            for match in matches:
                field_name = match.group(1)
                if field_name in self.field_standards and field_name != self.field_standards[field_name]:
                    self.issues.append(FieldIssue(
                        file_path=str(file_path),
                        line_number=line_num,
                        issue_type="field_usage",
                        current_field=field_name,
                        suggested_field=self.field_standards[field_name],
                        context=line.strip()
                    ))
    
    def _find_line_number(self, content: str, search_text: str) -> int:
        """æŸ¥æ‰¾æ–‡æœ¬åœ¨æ–‡ä»¶ä¸­çš„è¡Œå·"""
        lines = content.split('\n')
        for i, line in enumerate(lines, 1):
            if search_text in line:
                return i
        return 1
    
    def generate_report(self) -> str:
        """ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š"""
        if not self.issues:
            return "âœ… æœªå‘ç°å­—æ®µæ ‡å‡†åŒ–é—®é¢˜ï¼"
        
        report = []
        report.append(f"ğŸ“Š å­—æ®µæ ‡å‡†åŒ–æ£€æŸ¥æŠ¥å‘Š")
        report.append(f"=" * 50)
        report.append(f"æ€»è®¡å‘ç° {len(self.issues)} ä¸ªé—®é¢˜\n")
        
        # æŒ‰æ–‡ä»¶åˆ†ç»„
        issues_by_file = {}
        for issue in self.issues:
            if issue.file_path not in issues_by_file:
                issues_by_file[issue.file_path] = []
            issues_by_file[issue.file_path].append(issue)
        
        for file_path, file_issues in issues_by_file.items():
            report.append(f"ğŸ“ {file_path}")
            for issue in file_issues:
                report.append(f"  ğŸ“ ç¬¬{issue.line_number}è¡Œ: {issue.current_field} â†’ {issue.suggested_field}")
                report.append(f"     ä¸Šä¸‹æ–‡: {issue.context}")
            report.append("")
        
        return "\n".join(report)
    
    def generate_fix_script(self) -> str:
        """ç”Ÿæˆä¿®å¤è„šæœ¬"""
        if not self.issues:
            return "# æ²¡æœ‰éœ€è¦ä¿®å¤çš„é—®é¢˜"
        
        script_lines = []
        script_lines.append("#!/bin/bash")
        script_lines.append("# å­—æ®µæ ‡å‡†åŒ–ä¿®å¤è„šæœ¬")
        script_lines.append("# è¯·ä»”ç»†æ£€æŸ¥æ¯ä¸ªæ›¿æ¢æ“ä½œï¼Œç¡®è®¤æ— è¯¯åæ‰§è¡Œ")
        script_lines.append("")
        
        # æŒ‰æ–‡ä»¶åˆ†ç»„ç”Ÿæˆä¿®å¤å‘½ä»¤
        issues_by_file = {}
        for issue in self.issues:
            if issue.file_path not in issues_by_file:
                issues_by_file[issue.file_path] = []
            issues_by_file[issue.file_path].append(issue)
        
        for file_path, file_issues in issues_by_file.items():
            script_lines.append(f"echo 'ä¿®å¤æ–‡ä»¶: {file_path}'")
            
            for issue in file_issues:
                if issue.issue_type == "field_name":
                    # JSONå­—æ®µæ›¿æ¢
                    script_lines.append(
                        f"sed -i 's/\"{issue.current_field}\":/\"{issue.suggested_field}\":/g' {file_path}"
                    )
                elif issue.issue_type == "field_usage":
                    # ä»£ç ä¸­çš„å­—æ®µä½¿ç”¨æ›¿æ¢ï¼ˆéœ€è¦æ›´ç²¾ç¡®çš„æ›¿æ¢ï¼‰
                    script_lines.append(f"# æ‰‹åŠ¨æ£€æŸ¥å¹¶æ›¿æ¢: {issue.current_field} â†’ {issue.suggested_field}")
            
            script_lines.append("")
        
        return "\n".join(script_lines)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å­—æ®µæ ‡å‡†åŒ–æ£€æŸ¥å·¥å…·")
    parser.add_argument("--check", action="store_true", help="æ£€æŸ¥å­—æ®µæ ‡å‡†åŒ–é—®é¢˜")
    parser.add_argument("--report", action="store_true", help="ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š")
    parser.add_argument("--fix-script", action="store_true", help="ç”Ÿæˆä¿®å¤è„šæœ¬")
    parser.add_argument("--path", default=".", help="æ£€æŸ¥è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•")
    
    args = parser.parse_args()
    
    checker = FieldStandardizationChecker(args.path)
    
    if args.check or args.report:
        issues = checker.check_all_files()
        
        if args.report:
            print(checker.generate_report())
        else:
            print(f"å‘ç° {len(issues)} ä¸ªå­—æ®µæ ‡å‡†åŒ–é—®é¢˜")
            for issue in issues[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"  {issue.file_path}:{issue.line_number} {issue.current_field} â†’ {issue.suggested_field}")
            if len(issues) > 10:
                print(f"  ... è¿˜æœ‰ {len(issues) - 10} ä¸ªé—®é¢˜")
    
    if args.fix_script:
        issues = checker.check_all_files()
        script = checker.generate_fix_script()
        
        with open("fix_field_standardization.sh", "w") as f:
            f.write(script)
        print("âœ… ä¿®å¤è„šæœ¬å·²ç”Ÿæˆ: fix_field_standardization.sh")


if __name__ == "__main__":
    main() 