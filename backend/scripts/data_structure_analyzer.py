#!/usr/bin/env python3
"""
RSSè®¢é˜…æºåŸç”Ÿæ•°æ®ç»“æ„åˆ†æå·¥å…·
ç”¨äºæ·±åº¦åˆ†æ6ç§è®¢é˜…æºçš„æ•°æ®ç»“æ„å’Œå­—æ®µç‰¹å¾
"""

import json
import time
import asyncio
import aiohttp
from datetime import datetime
from typing import Dict, List, Any, Optional
import feedparser
from pathlib import Path
import hashlib

class RSSDataStructureAnalyzer:
    """RSSæ•°æ®ç»“æ„åˆ†æå™¨"""
    
    def __init__(self):
        self.results = {
            "analysis_time": datetime.now().isoformat(),
            "platforms": {},
            "unified_schema": {},
            "field_statistics": {},
            "recommendations": {}
        }
        
        # ä»è®¢é˜…æ¨¡æ¿é…ç½®åŠ è½½æµ‹è¯•ç”¨ä¾‹
        self.templates = self._load_templates()
        
        # è¯·æ±‚é…ç½®ï¼šçªç ´429é™åˆ¶
        self.request_config = {
            "timeout": 30,
            "retry_count": 3,
            "retry_delay": 2,  # ç§’
            "headers": {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                "Accept": "application/rss+xml, application/xml, text/xml",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Cache-Control": "no-cache"
            }
        }
    
    def _load_templates(self) -> Dict:
        """åŠ è½½è®¢é˜…æ¨¡æ¿é…ç½®"""
        template_path = Path(__file__).parent.parent / "app/config/subscription_templates.json"
        with open(template_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    async def analyze_all_platforms(self):
        """åˆ†ææ‰€æœ‰å¹³å°çš„æ•°æ®ç»“æ„"""
        print(f"ğŸš€ å¼€å§‹åˆ†æ6ç§è®¢é˜…æºçš„åŸç”Ÿæ•°æ®ç»“æ„...")
        
        # å®šä¹‰æµ‹è¯•ç”¨ä¾‹ï¼Œä¼˜å…ˆå¤„ç†èƒ½è®¿é—®çš„æº
        test_cases = [
            # Bç«™ - ä¼˜å…ˆæµ‹è¯•ï¼ˆå·²çŸ¥å¯ç”¨ï¼‰
            {
                "template_id": "bilibili_user_videos",
                "test_params": [
                    {"uid": "2267573", "name": "DIYgod"},
                    {"uid": "297572288", "name": "å¾·å·æ‰‘å…‹æœ¨å¤´å“Ÿ"},
                    {"uid": "946974", "name": "å½±è§†é£“é£"}  # æ–°å¢æµ‹è¯•ç”¨ä¾‹
                ]
            },
            {
                "template_id": "bilibili_user_dynamics", 
                "test_params": [
                    {"uid": "297572288", "name": "å¾·å·æ‰‘å…‹æœ¨å¤´å“Ÿ"},
                    {"uid": "2267573", "name": "DIYgod"}
                ]
            },
            
            # å¾®åš - ä½¿ç”¨å¤šç§ç­–ç•¥çªç ´é™åˆ¶
            {
                "template_id": "weibo_user_posts",
                "test_params": [
                    {"uid": "1195230310", "name": "æµ‹è¯•ç”¨æˆ·1"},
                    {"uid": "1560906700", "name": "æµ‹è¯•ç”¨æˆ·2"}
                ]
            },
            {
                "template_id": "weibo_keyword_search",
                "test_params": [
                    {"keyword": "äººå·¥æ™ºèƒ½"},
                    {"keyword": "ç¨‹åºå‘˜"}
                ]
            },
            
            # å³åˆ» - å¤šå®ä¾‹æµ‹è¯•
            {
                "template_id": "jike_user_posts",
                "test_params": [
                    {"id": "82D23B32-CF36-4C59-AD6F-D05E3552CBF3", "name": "æµ‹è¯•ç”¨æˆ·1"}
                ]
            },
            {
                "template_id": "jike_topic_posts", 
                "test_params": [
                    {"id": "556688fae4b00c57d9dd46ee", "name": "æµ‹è¯•åœˆå­1"}
                ]
            }
        ]
        
        # å¹¶å‘åˆ†æï¼Œä½†æ§åˆ¶å¹¶å‘æ•°é¿å…429
        semaphore = asyncio.Semaphore(2)  # æœ€å¤š2ä¸ªå¹¶å‘è¯·æ±‚
        tasks = []
        
        for test_case in test_cases:
            for params in test_case["test_params"]:
                task = self._analyze_single_source(
                    semaphore, test_case["template_id"], params
                )
                tasks.append(task)
        
        # æ‰§è¡Œåˆ†æ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        for result in results:
            if isinstance(result, dict) and not isinstance(result, Exception):
                platform = result.get("platform")
                if platform:
                    if platform not in self.results["platforms"]:
                        self.results["platforms"][platform] = {
                            "templates": {},
                            "common_fields": set(),
                            "unique_fields": set()
                        }
                    
                    template_id = result.get("template_id")
                    self.results["platforms"][platform]["templates"][template_id] = result
        
        # ç”Ÿæˆç»Ÿä¸€æ•°æ®æ¨¡å¼
        self._generate_unified_schema()
        
        # ç”Ÿæˆå­—æ®µç»Ÿè®¡
        self._generate_field_statistics()
        
        # ç”Ÿæˆå»ºè®®
        self._generate_recommendations()
        
        return self.results
    
    async def _analyze_single_source(self, semaphore: asyncio.Semaphore, 
                                   template_id: str, params: Dict) -> Dict:
        """åˆ†æå•ä¸ªè®¢é˜…æº"""
        async with semaphore:
            try:
                # è·å–æ¨¡æ¿é…ç½®
                template = next(
                    t for t in self.templates["templates"] 
                    if t["template_id"] == template_id
                )
                
                # æ„å»ºRSS URL
                url_template = template["url_template"]
                rss_url = url_template.format(**params)
                
                print(f"ğŸ“¡ åˆ†æ {template['platform']} - {template['template_name']}")
                print(f"   URL: {rss_url}")
                
                # è·å–RSSæ•°æ®
                rss_data = await self._fetch_rss_with_retry(rss_url)
                if not rss_data:
                    return {"error": f"æ— æ³•è·å–RSSæ•°æ®: {rss_url}"}
                
                # è§£ææ•°æ®ç»“æ„
                parsed_data = feedparser.parse(rss_data)
                
                # åˆ†æç»“æ„
                analysis = self._analyze_rss_structure(parsed_data, template, params)
                
                # æ·»åŠ è¯·æ±‚é—´éš”ï¼Œé¿å…429
                await asyncio.sleep(1)
                
                return analysis
                
            except Exception as e:
                return {"error": str(e), "template_id": template_id, "params": params}
    
    async def _fetch_rss_with_retry(self, url: str) -> Optional[str]:
        """å¸¦é‡è¯•æœºåˆ¶çš„RSSè·å–"""
        for attempt in range(self.request_config["retry_count"]):
            try:
                async with aiohttp.ClientSession(
                    timeout=aiohttp.ClientTimeout(total=self.request_config["timeout"]),
                    headers=self.request_config["headers"]
                ) as session:
                    
                    async with session.get(url) as response:
                        if response.status == 200:
                            return await response.text()
                        elif response.status == 429:
                            wait_time = (2 ** attempt) * self.request_config["retry_delay"]
                            print(f"   âš ï¸  HTTP 429ï¼Œç­‰å¾… {wait_time}s åé‡è¯•...")
                            await asyncio.sleep(wait_time)
                        else:
                            print(f"   âŒ HTTP {response.status}: {await response.text()}")
                            return None
                            
            except Exception as e:
                print(f"   âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}")
                if attempt < self.request_config["retry_count"] - 1:
                    await asyncio.sleep(self.request_config["retry_delay"])
        
        return None
    
    def _analyze_rss_structure(self, parsed_data: Any, template: Dict, params: Dict) -> Dict:
        """åˆ†æRSSæ•°æ®ç»“æ„"""
        feed = parsed_data.feed
        entries = parsed_data.entries[:5]  # åˆ†æå‰5æ¡å†…å®¹
        
        analysis = {
            "template_id": template["template_id"],
            "platform": template["platform"],
            "template_name": template["template_name"],
            "test_params": params,
            "analysis_time": datetime.now().isoformat(),
            
            # Feedçº§åˆ«ä¿¡æ¯
            "feed_info": {
                "title": getattr(feed, 'title', ''),
                "description": getattr(feed, 'description', ''),
                "link": getattr(feed, 'link', ''),
                "language": getattr(feed, 'language', ''),
                "generator": getattr(feed, 'generator', ''),
                "updated": getattr(feed, 'updated', ''),
                "total_entries": len(parsed_data.entries)
            },
            
            # å†…å®¹å­—æ®µç»“æ„
            "content_schema": {},
            "field_types": {},
            "field_examples": {},
            "unique_fields": set(),
            "common_fields": set()
        }
        
        if entries:
            # åˆ†æç¬¬ä¸€æ¡å†…å®¹çš„å®Œæ•´ç»“æ„
            first_entry = entries[0]
            analysis["content_schema"] = self._extract_entry_fields(first_entry)
            
            # åˆ†ææ‰€æœ‰å­—æ®µçš„ç±»å‹å’Œç¤ºä¾‹
            for entry in entries:
                for field_name in dir(entry):
                    if not field_name.startswith('_'):
                        try:
                            field_value = getattr(entry, field_name)
                            if field_value and not callable(field_value):
                                # è®°å½•å­—æ®µç±»å‹
                                field_type = type(field_value).__name__
                                if field_name not in analysis["field_types"]:
                                    analysis["field_types"][field_name] = field_type
                                
                                # è®°å½•å­—æ®µç¤ºä¾‹ï¼ˆæˆªå–å‰100å­—ç¬¦ï¼‰
                                if field_name not in analysis["field_examples"]:
                                    example = str(field_value)[:100]
                                    analysis["field_examples"][field_name] = example
                        except:
                            pass
        
        # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
        analysis["unique_fields"] = list(analysis["unique_fields"])
        analysis["common_fields"] = list(analysis["common_fields"])
        
        return analysis
    
    def _extract_entry_fields(self, entry) -> Dict:
        """æå–æ¡ç›®çš„æ‰€æœ‰å­—æ®µ"""
        fields = {}
        
        for field_name in dir(entry):
            if not field_name.startswith('_'):
                try:
                    field_value = getattr(entry, field_name)
                    if field_value and not callable(field_value):
                        # ç‰¹æ®Šå¤„ç†ä¸€äº›å¤æ‚å­—æ®µ
                        if hasattr(field_value, '__dict__'):
                            fields[field_name] = str(field_value)
                        elif isinstance(field_value, (list, tuple)):
                            fields[field_name] = list(field_value)
                        else:
                            fields[field_name] = field_value
                except:
                    pass
        
        return fields
    
    def _generate_unified_schema(self):
        """ç”Ÿæˆç»Ÿä¸€çš„æ•°æ®æ¨¡å¼"""
        all_fields = {}
        
        for platform_name, platform_data in self.results["platforms"].items():
            for template_id, template_data in platform_data["templates"].items():
                if "field_types" in template_data:
                    for field_name, field_type in template_data["field_types"].items():
                        if field_name not in all_fields:
                            all_fields[field_name] = {
                                "type": field_type,
                                "platforms": [platform_name],
                                "count": 1
                            }
                        else:
                            if platform_name not in all_fields[field_name]["platforms"]:
                                all_fields[field_name]["platforms"].append(platform_name)
                            all_fields[field_name]["count"] += 1
        
        # è¯†åˆ«æ ¸å¿ƒå­—æ®µï¼ˆå‡ºç°åœ¨å¤šä¸ªå¹³å°çš„å­—æ®µï¼‰
        core_fields = {
            field_name: field_info 
            for field_name, field_info in all_fields.items()
            if field_info["count"] >= 2
        }
        
        self.results["unified_schema"] = {
            "all_fields": all_fields,
            "core_fields": core_fields,
            "mvp_display_fields": [
                "title", "link", "description", "published", "author"
            ]
        }
    
    def _generate_field_statistics(self):
        """ç”Ÿæˆå­—æ®µç»Ÿè®¡ä¿¡æ¯"""
        total_platforms = len(self.results["platforms"])
        total_templates = sum(
            len(p["templates"]) for p in self.results["platforms"].values()
        )
        
        field_frequency = {}
        for platform_data in self.results["platforms"].values():
            for template_data in platform_data["templates"].values():
                if "field_types" in template_data:
                    for field_name in template_data["field_types"]:
                        field_frequency[field_name] = field_frequency.get(field_name, 0) + 1
        
        # æŒ‰é¢‘ç‡æ’åº
        sorted_fields = sorted(
            field_frequency.items(), 
            key=lambda x: x[1], 
            reverse=True
        )
        
        self.results["field_statistics"] = {
            "total_platforms": total_platforms,
            "total_templates": total_templates,
            "total_unique_fields": len(field_frequency),
            "high_frequency_fields": sorted_fields[:10],
            "universal_fields": [
                field for field, count in sorted_fields 
                if count >= total_templates * 0.8
            ]
        }
    
    def _generate_recommendations(self):
        """ç”ŸæˆMVPé˜¶æ®µå»ºè®®"""
        self.results["recommendations"] = {
            "mvp_display_fields": {
                "essential": ["title", "link", "published"],
                "recommended": ["description", "author"],
                "optional": ["tags", "updated", "id"]
            },
            
            "ui_design_suggestions": {
                "title": "ä¸»æ ‡é¢˜ï¼Œæ”¯æŒé“¾æ¥è·³è½¬",
                "published": "ç›¸å¯¹æ—¶é—´æ˜¾ç¤ºï¼ˆå¦‚'2å°æ—¶å‰'ï¼‰",
                "description": "æ‘˜è¦ï¼Œæˆªå–200å­—ç¬¦ï¼Œæ”¯æŒå±•å¼€",
                "author": "ä½œè€…ä¿¡æ¯ï¼Œå¯é€‰æ˜¾ç¤º",
                "platform_icon": "æ ¹æ®template.platformæ˜¾ç¤ºå¯¹åº”icon"
            },
            
            "data_processing_priorities": [
                "å®ç°RSSæºè®¿é—®é¢‘ç‡æ§åˆ¶",
                "ç»Ÿä¸€æ—¶é—´æ ¼å¼å¤„ç†ï¼ˆpublishedå­—æ®µï¼‰",
                "HTMLæ ‡ç­¾æ¸…ç†ï¼ˆdescriptionå­—æ®µï¼‰",
                "å†…å®¹å»é‡æœºåˆ¶ï¼ˆåŸºäºlinkæˆ–idï¼‰",
                "é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥"
            ],
            
            "technical_implementation": {
                "backend_field_mapping": {
                    "title": "entry.title",
                    "link": "entry.link", 
                    "description": "clean_html(entry.description)",
                    "published_at": "parse_datetime(entry.published)",
                    "author": "entry.author or extract_from_title()",
                    "content_hash": "generate_hash(entry.link + entry.title)"
                },
                
                "frontend_display_props": {
                    "title": "string",
                    "link": "string", 
                    "description": "string (max 200 chars)",
                    "published_at": "Date object",
                    "author": "string | null",
                    "platform": "string",
                    "template_name": "string"
                }
            }
        }
    
    def save_results(self, output_file: str = None):
        """ä¿å­˜åˆ†æç»“æœ"""
        if not output_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"rss_data_structure_analysis_{timestamp}.json"
        
        output_path = Path(__file__).parent.parent / "docs/analysis" / output_file
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # å¤„ç†setç±»å‹ä»¥ä¾¿JSONåºåˆ—åŒ–
        def serialize_sets(obj):
            if isinstance(obj, set):
                return list(obj)
            return obj
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2, default=serialize_sets)
        
        print(f"ğŸ“„ åˆ†æç»“æœå·²ä¿å­˜è‡³: {output_path}")
        return output_path

async def main():
    """ä¸»å‡½æ•°"""
    analyzer = RSSDataStructureAnalyzer()
    
    print("=" * 60)
    print("ğŸ” RSSè®¢é˜…æºåŸç”Ÿæ•°æ®ç»“æ„æ·±åº¦åˆ†æ")
    print("=" * 60)
    
    # æ‰§è¡Œåˆ†æ
    results = await analyzer.analyze_all_platforms()
    
    # ä¿å­˜ç»“æœ
    output_path = analyzer.save_results()
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“Š åˆ†ææ‘˜è¦")
    print("=" * 60)
    
    platforms = results.get("platforms", {})
    print(f"âœ… æˆåŠŸåˆ†æå¹³å°æ•°: {len(platforms)}")
    
    for platform_name, platform_data in platforms.items():
        successful_templates = len(platform_data.get("templates", {}))
        print(f"   ğŸ“± {platform_name}: {successful_templates}ä¸ªæ¨¡æ¿")
    
    if "field_statistics" in results:
        stats = results["field_statistics"]
        print(f"ğŸ”¢ å‘ç°å­—æ®µæ€»æ•°: {stats.get('total_unique_fields', 0)}")
        print(f"ğŸŒŸ é€šç”¨å­—æ®µæ•°é‡: {len(stats.get('universal_fields', []))}")
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {output_path}")
    print("ğŸš€ å»ºè®®ä¸‹ä¸€æ­¥: åŸºäºåˆ†æç»“æœä¼˜åŒ–ç”¨æˆ·ç•Œé¢å’Œæ•°æ®å¤„ç†é€»è¾‘")

if __name__ == "__main__":
    asyncio.run(main()) 