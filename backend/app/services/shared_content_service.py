#!/usr/bin/env python3
"""
å…±äº«å†…å®¹æœåŠ¡
æ•´åˆå†…å®¹å»é‡å’Œç”¨æˆ·å…³ç³»ç®¡ç†ï¼Œæä¾›å®Œæ•´çš„å†…å®¹å­˜å‚¨å’ŒæŸ¥è¯¢åŠŸèƒ½
"""

import json
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from loguru import logger

from ..core.database_manager import get_db_connection, get_db_transaction
from .content_deduplication_service import ContentDeduplicationService
from .user_content_relation_service import UserContentRelationService


class SharedContentService:
    """å…±äº«å†…å®¹æœåŠ¡"""
    
    def __init__(self, db_path: str = "data/rss_subscriber.db"):
        self.db_path = db_path
        self.dedup_service = ContentDeduplicationService(db_path)
        self.relation_service = UserContentRelationService(db_path)
        logger.info("ğŸ”§ å…±äº«å†…å®¹æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    async def store_rss_content(
        self, 
        rss_items: List[Dict[str, Any]], 
        subscription_id: int, 
        user_id: int
    ) -> Dict[str, Any]:
        """
        å­˜å‚¨RSSå†…å®¹åˆ°æ–°æ¶æ„
        
        Args:
            rss_items: RSSå†…å®¹é¡¹åˆ—è¡¨
            subscription_id: è®¢é˜…ID
            user_id: ç”¨æˆ·ID
            
        Returns:
            Dict: å¤„ç†ç»“æœç»Ÿè®¡
        """
        try:
            processed_count = 0
            new_content_count = 0
            reused_content_count = 0
            need_ai_processing_ids = []  # ğŸ”¥ æ”¹åï¼šéœ€è¦AIå¤„ç†çš„å†…å®¹IDï¼ˆä¸ç®¡æ–°æ—§ï¼‰
            
            logger.info(f"å¼€å§‹å¤„ç†RSSå†…å®¹: {len(rss_items)}æ¡, user_id={user_id}, subscription_id={subscription_id}")
            
            for item in rss_items:
                try:
                    # 1. æŸ¥æ‰¾æˆ–åˆ›å»ºå…±äº«å†…å®¹
                    content_id, is_new = await self.dedup_service.find_or_create_content(item)
                    
                    # 2. å»ºç«‹ç”¨æˆ·å…³ç³»ï¼ˆ24å°æ—¶æœ‰æ•ˆæœŸï¼‰
                    relation_id = await self.relation_service.create_relation(
                        user_id=user_id,
                        content_id=content_id,
                        subscription_id=subscription_id,
                        expires_hours=24
                    )
                    
                    # 3. å¤„ç†åª’ä½“é¡¹
                    if item.get('media_items'):
                        await self._store_media_items(content_id, item['media_items'])
                    
                    # 4. æ£€æŸ¥æ˜¯å¦éœ€è¦AIå¤„ç†ï¼ˆç›´æ¥æ£€æŸ¥AIå­—æ®µæ˜¯å¦ä¸ºç©ºï¼‰
                    if await self._needs_ai_processing(content_id):
                        need_ai_processing_ids.append(content_id)
                    
                    # 5. ç»Ÿè®¡
                    if is_new:
                        new_content_count += 1
                        logger.debug(f"åˆ›å»ºæ–°å†…å®¹: content_id={content_id}, title={item.get('title', '')[:50]}...")
                    else:
                        reused_content_count += 1
                        logger.debug(f"å¤ç”¨ç°æœ‰å†…å®¹: content_id={content_id}")
                    
                    processed_count += 1
                    
                except Exception as e:
                    logger.error(f"å¤„ç†å•æ¡RSSå†…å®¹å¤±è´¥: {e}, item={item.get('title', 'Unknown')}")
                    continue
            
            result = {
                'total_processed': processed_count,
                'new_content': new_content_count,
                'reused_content': reused_content_count,
                'deduplication_rate': round(reused_content_count / max(processed_count, 1) * 100, 1),
                'need_ai_processing_ids': need_ai_processing_ids  # ğŸ”¥ è¿”å›éœ€è¦AIå¤„ç†çš„å†…å®¹IDåˆ—è¡¨
            }
            
            logger.success(f"RSSå†…å®¹å¤„ç†å®Œæˆ: {result}")
            return result
            
        except Exception as e:
            logger.error(f"å­˜å‚¨RSSå†…å®¹å¤±è´¥: {e}")
            raise
    
    async def get_user_contents(
        self, 
        user_id: int, 
        **filters
    ) -> List[Dict[str, Any]]:
        """
        è·å–ç”¨æˆ·å†…å®¹åˆ—è¡¨
        
        Args:
            user_id: ç”¨æˆ·ID
            **filters: ç­›é€‰æ¡ä»¶
            
        Returns:
            List[Dict]: å†…å®¹åˆ—è¡¨
        """
        try:
            with get_db_connection() as conn:
                cursor = conn.cursor()
                
                # åŸºç¡€æŸ¥è¯¢
                query = """
                    SELECT 
                        c.id as content_id,
                        c.title,
                        c.author,
                        c.published_at,
                        c.original_link,
                        c.description,
                        c.description_text,
                        c.summary,
                        c.tags,
                        c.platform,
                        c.content_type,
                        c.cover_image,
                        c.feed_title,
                        r.subscription_id,
                        r.is_read,
                        r.is_favorited,
                        r.read_at,
                        r.personal_tags,
                        r.expires_at,
                        us.custom_name as subscription_name
                    FROM shared_contents c
                    JOIN user_content_relations r ON c.id = r.content_id
                    LEFT JOIN user_subscriptions us ON r.subscription_id = us.id
                    WHERE r.user_id = ? 
                      AND r.expires_at > datetime('now')
                """
                
                # åº”ç”¨ç­›é€‰æ¡ä»¶
                params = [user_id]
                
                if filters.get('platform'):
                    query += " AND c.platform = ?"
                    params.append(filters['platform'])
                
                if filters.get('subscription_id'):
                    query += " AND r.subscription_id = ?"
                    params.append(filters['subscription_id'])
                
                if filters.get('is_read') is not None:
                    query += " AND r.is_read = ?"
                    params.append(filters['is_read'])
                
                if filters.get('is_favorited') is not None:
                    query += " AND r.is_favorited = ?"
                    params.append(filters['is_favorited'])
                
                if filters.get('content_type'):
                    query += " AND c.content_type = ?"
                    params.append(filters['content_type'])
                
                # æ’åº
                query += " ORDER BY c.published_at DESC"
                
                # åˆ†é¡µ
                limit = filters.get('limit', 20)
                offset = filters.get('offset', 0)
                query += " LIMIT ? OFFSET ?"
                params.extend([limit, offset])
                
                cursor.execute(query, params)
                rows = cursor.fetchall()
                
                # å¤„ç†ç»“æœ
                contents = []
                for row in rows:
                    # è·å–åª’ä½“é¡¹
                    media_items = await self._get_content_media_items(row[0])
                    
                    content = {
                        'content_id': row[0],
                        'title': row[1],
                        'author': row[2],
                        'published_at': row[3],
                        'original_link': row[4],
                        'description': row[5],
                        'description_text': row[6],
                        'summary': row[7],
                        'tags': json.loads(row[8]) if row[8] else [],
                        'platform': row[9],
                        'content_type': row[10],
                        'cover_image': row[11],
                        'feed_title': row[12],
                        'subscription_id': row[13],
                        'is_read': bool(row[14]),
                        'is_favorited': bool(row[15]),
                        'read_at': row[16],
                        'personal_tags': json.loads(row[17]) if row[17] else [],
                        'expires_at': row[18],
                        'subscription_name': row[19],
                        'media_items': media_items
                    }
                    contents.append(content)
                
                logger.info(f"è·å–ç”¨æˆ·å†…å®¹: user_id={user_id}, è¿”å›{len(contents)}æ¡")
                return contents
                
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·å†…å®¹å¤±è´¥: {e}")
            return []
    
    async def update_content_status(
        self, 
        user_id: int, 
        content_id: int, 
        **updates
    ) -> bool:
        """
        æ›´æ–°å†…å®¹çŠ¶æ€
        
        Args:
            user_id: ç”¨æˆ·ID
            content_id: å†…å®¹ID
            **updates: æ›´æ–°å­—æ®µ
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            success = await self.relation_service.update_relation_status(
                user_id, content_id, **updates
            )
            
            if success:
                logger.info(f"æ›´æ–°å†…å®¹çŠ¶æ€æˆåŠŸ: user_id={user_id}, content_id={content_id}, updates={updates}")
            
            return success
            
        except Exception as e:
            logger.error(f"æ›´æ–°å†…å®¹çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    async def get_user_content_stats(self, user_id: int) -> Dict[str, Any]:
        """
        è·å–ç”¨æˆ·å†…å®¹ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            user_id: ç”¨æˆ·ID
            
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # è·å–åŸºç¡€ç»Ÿè®¡
            stats = await self.relation_service.get_user_content_stats(user_id)
            
            # æ·»åŠ ç³»ç»Ÿçº§ç»Ÿè®¡
            system_stats = await self.dedup_service.get_content_stats()
            stats.update({
                'system_stats': system_stats
            })
            
            return stats
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·å†…å®¹ç»Ÿè®¡å¤±è´¥: {e}")
            return {}
    
    async def _needs_ai_processing(self, content_id: int) -> bool:
        """
        æ£€æŸ¥å†…å®¹æ˜¯å¦éœ€è¦AIå¤„ç†ï¼ˆç›´æ¥æ£€æŸ¥AIå­—æ®µæ˜¯å¦ä¸ºç©ºï¼‰
        
        Args:
            content_id: å†…å®¹ID
            
        Returns:
            bool: Trueè¡¨ç¤ºéœ€è¦AIå¤„ç†ï¼ŒFalseè¡¨ç¤ºå·²ç»å¤„ç†è¿‡
        """
        try:
            with get_db_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT summary, tags 
                    FROM shared_contents 
                    WHERE id = ?
                """, (content_id,))
                
                result = cursor.fetchone()
                if not result:
                    # å†…å®¹ä¸å­˜åœ¨ï¼Œç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿ
                    return False
                
                summary, tags = result
                
                # æ£€æŸ¥æ‘˜è¦å’Œæ ‡ç­¾æ˜¯å¦ä¸ºç©º
                has_summary = summary and summary.strip()
                has_tags = tags and tags.strip()
                
                # åªè¦æœ‰ä¸€ä¸ªAIå­—æ®µä¸ºç©ºï¼Œå°±éœ€è¦å¤„ç†
                needs_processing = not (has_summary and has_tags)
                
                if needs_processing:
                    logger.debug(f"å†…å®¹éœ€è¦AIå¤„ç†: content_id={content_id}, summary={bool(has_summary)}, tags={bool(has_tags)}")
                
                return needs_processing
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥AIå¤„ç†éœ€æ±‚å¤±è´¥: {e}")
            # å‡ºé”™æ—¶ä¿å®ˆå¤„ç†ï¼Œè®¤ä¸ºéœ€è¦AIå¤„ç†
            return True

    async def get_contents_by_ids(self, content_ids: List[int]) -> List[Dict[str, Any]]:
        """
        æ ¹æ®content_idsæ‰¹é‡è·å–å†…å®¹ï¼ˆç”¨äºAIé¢„å¤„ç†ï¼‰
        
        Args:
            content_ids: å†…å®¹IDåˆ—è¡¨
            
        Returns:
            List[Dict]: å†…å®¹åˆ—è¡¨
        """
        if not content_ids:
            return []
            
        try:
            with get_db_connection() as conn:
                cursor = conn.cursor()
                
                # æ„å»ºæŸ¥è¯¢è¯­å¥
                placeholder = ','.join(['?'] * len(content_ids))
                query = f"""
                    SELECT 
                        id as content_id,
                        title,
                        author,
                        published_at,
                        original_link,
                        description,
                        description_text,
                        summary,
                        tags,
                        platform,
                        content_type,
                        cover_image,
                        feed_title,
                        content_hash
                    FROM shared_contents
                    WHERE id IN ({placeholder})
                    ORDER BY id DESC
                """
                
                cursor.execute(query, content_ids)
                rows = cursor.fetchall()
                
                # å¤„ç†ç»“æœ
                contents = []
                for row in rows:
                    content = {
                        'content_id': row[0],
                        'title': row[1],
                        'author': row[2],
                        'published_at': row[3],
                        'original_link': row[4],
                        'description': row[5],
                        'description_text': row[6],
                        'summary': row[7],
                        'tags': json.loads(row[8]) if row[8] else [],
                        'platform': row[9],
                        'content_type': row[10],
                        'cover_image': row[11],
                        'feed_title': row[12],
                        'content_hash': row[13]
                    }
                    contents.append(content)
                
                logger.info(f"æ‰¹é‡è¯»å–å†…å®¹: {len(content_ids)}ä¸ªID, è¿”å›{len(contents)}æ¡å†…å®¹")
                return contents
                
        except Exception as e:
            logger.error(f"æ‰¹é‡è¯»å–å†…å®¹å¤±è´¥: {e}")
            return []

    async def get_content_detail(self, content_id: int, user_id: int) -> Optional[Dict[str, Any]]:
        """
        è·å–å†…å®¹è¯¦æƒ…
        
        Args:
            content_id: å†…å®¹ID
            user_id: ç”¨æˆ·ID
            
        Returns:
            Optional[Dict]: å†…å®¹è¯¦æƒ…
        """
        try:
            with get_db_connection() as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT 
                        c.*,
                        r.is_read,
                        r.is_favorited,
                        r.read_at,
                        r.personal_tags,
                        r.subscription_id,
                        us.custom_name as subscription_name
                    FROM shared_contents c
                    LEFT JOIN user_content_relations r ON c.id = r.content_id AND r.user_id = ?
                    LEFT JOIN user_subscriptions us ON r.subscription_id = us.id
                    WHERE c.id = ?
                """, (user_id, content_id))
                
                row = cursor.fetchone()
                if not row:
                    return None
                
                # è·å–åª’ä½“é¡¹
                media_items = await self._get_content_media_items(content_id)
                
                content = {
                    'content_id': row[0],
                    'title': row[1],
                    'description': row[2],
                    'description_text': row[3],
                    'author': row[4],
                    'published_at': row[5],
                    'original_link': row[6],
                    'content_type': row[7],
                    'platform': row[8],
                    'content_hash': row[9],
                    'guid': row[10],
                    'feed_title': row[11],
                    'feed_description': row[12],
                    'feed_link': row[13],
                    'feed_image_url': row[14],
                    'feed_last_build_date': row[15],
                    'cover_image': row[16],
                    'summary': row[17],
                    'tags': json.loads(row[18]) if row[18] else [],
                    'created_at': row[19],
                    'updated_at': row[20],
                    'is_read': bool(row[21]) if row[21] is not None else False,
                    'is_favorited': bool(row[22]) if row[22] is not None else False,
                    'read_at': row[23],
                    'personal_tags': json.loads(row[24]) if row[24] else [],
                    'subscription_id': row[25],
                    'subscription_name': row[26],
                    'media_items': media_items
                }
                
                return content
                
        except Exception as e:
            logger.error(f"è·å–å†…å®¹è¯¦æƒ…å¤±è´¥: {e}")
            return None
    
    async def _store_media_items(self, content_id: int, media_items: List[Dict[str, Any]]) -> None:
        """å­˜å‚¨åª’ä½“é¡¹"""
        try:
            with get_db_transaction() as conn:
                cursor = conn.cursor()
                
                for i, item in enumerate(media_items):
                    cursor.execute("""
                        INSERT INTO shared_content_media_items (
                            content_id, url, media_type, description, duration, sort_order
                        ) VALUES (?, ?, ?, ?, ?, ?)
                    """, (
                        content_id,
                        item.get('url', ''),
                        item.get('type', 'image'),
                        item.get('description', ''),
                        item.get('duration'),
                        i
                    ))
                
                logger.debug(f"å­˜å‚¨åª’ä½“é¡¹: content_id={content_id}, count={len(media_items)}")
                
        except Exception as e:
            logger.error(f"å­˜å‚¨åª’ä½“é¡¹å¤±è´¥: {e}")
    
    async def _get_content_media_items(self, content_id: int) -> List[Dict[str, Any]]:
        """è·å–å†…å®¹åª’ä½“é¡¹"""
        try:
            with get_db_connection() as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT url, media_type, description, duration
                    FROM shared_content_media_items
                    WHERE content_id = ?
                    ORDER BY sort_order
                """, (content_id,))
                
                rows = cursor.fetchall()
                media_items = []
                
                for row in rows:
                    media_item = {
                        'url': row[0],
                        'type': row[1],
                        'description': row[2],
                        'duration': row[3]
                    }
                    media_items.append(media_item)
                
                return media_items
                
        except Exception as e:
            logger.error(f"è·å–åª’ä½“é¡¹å¤±è´¥: {e}")
            return []
    
    async def cleanup_expired_content(self) -> Dict[str, int]:
        """æ¸…ç†è¿‡æœŸå†…å®¹"""
        try:
            # æ¸…ç†è¿‡æœŸå…³ç³»å’Œå­¤ç«‹å†…å®¹
            deleted_relations = await self.relation_service.cleanup_expired_relations()
            
            return {
                'deleted_relations': deleted_relations,
                'message': 'è¿‡æœŸå†…å®¹æ¸…ç†å®Œæˆ'
            }
            
        except Exception as e:
            logger.error(f"æ¸…ç†è¿‡æœŸå†…å®¹å¤±è´¥: {e}")
            return {'error': str(e)}
    
    async def search_user_contents(
        self, 
        user_id: int, 
        keyword: str, 
        **filters
    ) -> List[Dict[str, Any]]:
        """
        æœç´¢ç”¨æˆ·å†…å®¹
        
        Args:
            user_id: ç”¨æˆ·ID
            keyword: æœç´¢å…³é”®è¯
            **filters: å…¶ä»–ç­›é€‰æ¡ä»¶
            
        Returns:
            List[Dict]: æœç´¢ç»“æœ
        """
        try:
            with get_db_connection() as conn:
                cursor = conn.cursor()
                
                query = """
                    SELECT 
                        c.id as content_id,
                        c.title,
                        c.author,
                        c.published_at,
                        c.original_link,
                        c.description_text,
                        c.platform,
                        c.content_type,
                        r.subscription_id,
                        r.is_read,
                        r.is_favorited,
                        us.custom_name as subscription_name
                    FROM shared_contents c
                    JOIN user_content_relations r ON c.id = r.content_id
                    LEFT JOIN user_subscriptions us ON r.subscription_id = us.id
                    WHERE r.user_id = ? 
                      AND r.expires_at > datetime('now')
                      AND (c.title LIKE ? OR c.description_text LIKE ? OR c.author LIKE ?)
                """
                
                params = [user_id, f'%{keyword}%', f'%{keyword}%', f'%{keyword}%']
                
                # åº”ç”¨å…¶ä»–ç­›é€‰æ¡ä»¶
                if filters.get('platform'):
                    query += " AND c.platform = ?"
                    params.append(filters['platform'])
                
                query += " ORDER BY c.published_at DESC"
                
                # åˆ†é¡µ
                limit = filters.get('limit', 20)
                offset = filters.get('offset', 0)
                query += " LIMIT ? OFFSET ?"
                params.extend([limit, offset])
                
                cursor.execute(query, params)
                rows = cursor.fetchall()
                
                contents = []
                for row in rows:
                    content = {
                        'content_id': row[0],
                        'title': row[1],
                        'author': row[2],
                        'published_at': row[3],
                        'original_link': row[4],
                        'description_text': row[5],
                        'platform': row[6],
                        'content_type': row[7],
                        'subscription_id': row[8],
                        'is_read': bool(row[9]),
                        'is_favorited': bool(row[10]),
                        'subscription_name': row[11]
                    }
                    contents.append(content)
                
                logger.info(f"æœç´¢ç”¨æˆ·å†…å®¹: user_id={user_id}, keyword={keyword}, ç»“æœ{len(contents)}æ¡")
                return contents
                
        except Exception as e:
            logger.error(f"æœç´¢ç”¨æˆ·å†…å®¹å¤±è´¥: {e}")
            return []


# åˆ›å»ºå…¨å±€å®ä¾‹
shared_content_service = SharedContentService() 